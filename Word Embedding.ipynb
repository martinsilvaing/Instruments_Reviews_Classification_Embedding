{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.random import seed # for reproducible results\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed # TensorFlow has its own random number generator\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A195EZSQDW3E21</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Rick Bennette \"Rick Bennette\"</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>The primary job of this device is to block the...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>It Does The Job Well</td>\n",
       "      <td>1377648000</td>\n",
       "      <td>08 28, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2C00NNG1ZQQG2</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>RustyBill \"Sunday Rocker\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Nice windscreen protects my MXL mic and preven...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>GOOD WINDSCREEN FOR THE MONEY</td>\n",
       "      <td>1392336000</td>\n",
       "      <td>02 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A94QU4C90B1AX</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>SEAN MASLANKA</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This pop filter is great. It looks and perform...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No more pops when I record my vocals.</td>\n",
       "      <td>1392940800</td>\n",
       "      <td>02 21, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "2  A195EZSQDW3E21  1384719342   \n",
       "3  A2C00NNG1ZQQG2  1384719342   \n",
       "4   A94QU4C90B1AX  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "2                     Rick Bennette \"Rick Bennette\"    [1, 1]   \n",
       "3                         RustyBill \"Sunday Rocker\"    [0, 0]   \n",
       "4                                     SEAN MASLANKA    [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Not much to write about here, but it does exac...      5.0   \n",
       "1  The product does exactly as it should and is q...      5.0   \n",
       "2  The primary job of this device is to block the...      5.0   \n",
       "3  Nice windscreen protects my MXL mic and preven...      5.0   \n",
       "4  This pop filter is great. It looks and perform...      5.0   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \n",
       "0                                   good      1393545600  02 28, 2014  \n",
       "1                                   Jake      1363392000  03 16, 2013  \n",
       "2                   It Does The Job Well      1377648000  08 28, 2013  \n",
       "3          GOOD WINDSCREEN FOR THE MONEY      1392336000  02 14, 2014  \n",
       "4  No more pops when I record my vocals.      1392940800  02 21, 2014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv('Musical_instruments_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             reviewText  overall\n",
      "8588  I can't say much about this product.  I tried ...      0.0\n",
      "7259  These are fine but didn't fit well; but they a...      0.0\n",
      "5129  I bought this pedal years ago, and like most g...      0.0\n",
      "8452  This delay is really nice, especially for the ...      1.0\n",
      "4439  This system works just okay.  Try to turn it u...      0.0\n"
     ]
    }
   ],
   "source": [
    "Feature_Columns = ['reviewText', 'overall']\n",
    "new_df = df[Feature_Columns]\n",
    "new_df = new_df.dropna()\n",
    "\n",
    "# convert to binary target\n",
    "def to_binary(df):\n",
    "    replacements = {1:0,\n",
    "                    2:0,\n",
    "                    3:0,\n",
    "                    4:1,\n",
    "                    5:1}\n",
    "    \n",
    "    #if statement so it applies the replace just the first time\n",
    "    if df['overall'].unique().sum() > 1:\n",
    "        df['overall'].replace(replacements, inplace=True)    \n",
    "    return df\n",
    "\n",
    "new_df = to_binary(new_df)\n",
    "\n",
    "# balance data\n",
    "target_numbers = new_df['overall'].value_counts()\n",
    "#extract portion of positives equal to the size of negatives and shuffle\n",
    "balanced_df = new_df.loc[new_df['overall']==1].sample(n=target_numbers[0], random_state=0)\n",
    "#append the negatives and shuffle\n",
    "balanced_df = balanced_df.append(new_df.loc[new_df['overall']==0]).sample(frac=1)\n",
    "\n",
    "print(balanced_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# convert reviews to list\n",
    "review_list = list(balanced_df['reviewText'])\n",
    "\n",
    "# separate words into tokens\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(review_list)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "# creates hashs \n",
    "encoded_docs = t.texts_to_sequences(review_list)\n",
    "\n",
    "# padd sequences (generates matrix with each word tag)\n",
    "max_length = 1000\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "\n",
    "# target\n",
    "labels = list(balanced_df['overall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a simple binary classification model. Importantly, the output from the Embedding layer will be 4 vectors of 8 dimensions each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 50)          564050    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 50001     \n",
      "=================================================================\n",
      "Total params: 614,051\n",
      "Trainable params: 614,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "2478/2478 [==============================] - 2s 661us/step - loss: 0.7067 - accuracy: 0.5391\n",
      "Epoch 2/10\n",
      "2478/2478 [==============================] - 1s 583us/step - loss: 0.6097 - accuracy: 0.6949\n",
      "Epoch 3/10\n",
      "2478/2478 [==============================] - 1s 565us/step - loss: 0.4292 - accuracy: 0.8801\n",
      "Epoch 4/10\n",
      "2478/2478 [==============================] - 1s 558us/step - loss: 0.2621 - accuracy: 0.9479\n",
      "Epoch 5/10\n",
      "2478/2478 [==============================] - 1s 552us/step - loss: 0.1623 - accuracy: 0.9762\n",
      "Epoch 6/10\n",
      "2478/2478 [==============================] - 1s 556us/step - loss: 0.1034 - accuracy: 0.9919\n",
      "Epoch 7/10\n",
      "2478/2478 [==============================] - 1s 550us/step - loss: 0.0686 - accuracy: 0.9960\n",
      "Epoch 8/10\n",
      "2478/2478 [==============================] - 1s 550us/step - loss: 0.0469 - accuracy: 0.9984\n",
      "Epoch 9/10\n",
      "2478/2478 [==============================] - 1s 551us/step - loss: 0.0333 - accuracy: 0.9992\n",
      "Epoch 10/10\n",
      "2478/2478 [==============================] - 1s 550us/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Accuracy: 100.000000\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=10, verbose=1)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.577113  ],\n",
       "       [0.59269047]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction in particular\n",
    "text = ['I dont like it', 'I like it']\n",
    "\n",
    "# pre-process\n",
    "text_encoded = t.texts_to_sequences(text)\n",
    "text_padded = pad_sequences(text_encoded, maxlen=max_length, padding='post')\n",
    "\n",
    "model.predict(text_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to remember that the data must always be balanced. This reduces the bias but forces us to drop important information of the predominating class.\n",
    "\n",
    "The model gives good results with sentences that contain the same words of the training subset, but does poorly with words that were not learned. This is one drawback of having a small dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It would be more suitable to use a machine learning algorithm, like KNN, Logistic Regression or Naive Bayes.\n",
    "- Another option is to train the neural network with a bigger dataset and then use it to classify this particular dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
